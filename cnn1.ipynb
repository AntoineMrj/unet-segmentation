{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset,DataLoader  # For custom data-sets\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys, getopt\n",
    "\n",
    "from PIL import Image\n",
    "from numpy import array\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PATHS\n",
    "_INPUT_PATH ='./input/background'\n",
    "_TRUTH_PATH ='./input/truth'\n",
    "_INPUT_PATH2 ='./input/to_predict'\n",
    "_TRUTH_PATH2 ='./input/to_predict_truth'\n",
    "\n",
    "# PARAMETERS\n",
    "num_epochs = 5\n",
    "batch_size = 2\n",
    "learning_rate = 0.001\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Convolutional neural network\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.down11 = nn.Sequential(\n",
    "            #nn.BatchNorm2d(3),\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1), #3= nb de channels (car image couleur), 32 = nombre de channels de sortie, kernel_size =3 taille du filtre de convolution (3x3), padding : 0 padding pour rester a \"same\" la meme taille d'image, padding 1 formule du padding voir sur internet mais pour simplifier c'est (kernel_size -1)/2\n",
    "            nn.ReLU())\n",
    "        self.down12 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.down21 = nn.Sequential(\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.down22 = nn.Sequential(\n",
    "            nn.Conv2d(64, 96, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.down31 = nn.Sequential(\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.Conv2d(96, 96, kernel_size=3, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.down32 = nn.Sequential(\n",
    "            nn.Conv2d(96, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.down41 = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.down42 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.down43 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.down44 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.down45 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.down46 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.down47 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.down48 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.down51 = nn.Sequential(\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.down52 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.down53 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.down54 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.up11 = nn.Sequential(\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ConvTranspose2d(512, 256, 3, stride=2, padding=1, output_padding=1), #output_padding=(input_shape[0],input_shape[1]) ajouter ca si ca marche pas Tester si c'est bien la taille originale qu'il faut mettre | essayer avec output_padding = 1\n",
    "            nn.ReLU())\n",
    "        self.up12 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, 3, stride=1, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.up21 = nn.Sequential(\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1), #output_padding=(input_shape[0],input_shape[1]) ajouter ca si ca marche pas Tester si c'est bien la taille originale qu'il faut mettre | essayer avec output_padding = 1\n",
    "            nn.ReLU())\n",
    "        self.up22 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 3, stride=1, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.up31 = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ConvTranspose2d(128, 96, 3, stride=2, padding=1, output_padding=1), #output_padding=(input_shape[0],input_shape[1]) ajouter ca si ca marche pas Tester si c'est bien la taille originale qu'il faut mettre | essayer avec output_padding = 1\n",
    "            nn.ReLU())\n",
    "        self.up32 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(192, 96, 3, stride=1, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.up41 = nn.Sequential(\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ConvTranspose2d(96, 64, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU())\n",
    "        self.up42 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 64, 3, stride=1, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.up43 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU())\n",
    "        self.up44 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 3, 3, stride=1, padding=1), #remettre 32 2 au lieu de 32 3\n",
    "            nn.ReLU())\n",
    "        self.up51 = nn.Sequential(\n",
    "            nn.BatchNorm2d(6), #remettre batchnorm 2\n",
    "            nn.ConvTranspose2d(6, 3, 3, stride=1, padding=1), #remettre 2 2 3 au lieu de 3 2 3\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, input):\n",
    "        #print('input : ', input.size())\n",
    "        down11 = self.down11(input)\n",
    "        down12 = self.down12(down11)\n",
    "        down21 = self.down21(down12)\n",
    "        down22 = self.down22(down21)\n",
    "        down31 = self.down31(down22)\n",
    "        down32 = self.down32(down31)\n",
    "        down41 = self.down41(down32)\n",
    "        down42 = self.down42(down41)\n",
    "        down43 = self.down43(down42)\n",
    "        down44 = self.down44(down43)\n",
    "        down45 = self.down45(down44)\n",
    "        down46 = self.down46(down45)\n",
    "        down47 = self.down47(down46)\n",
    "        down48 = self.down48(down47)\n",
    "        down51 = self.down51(down48)\n",
    "        down52 = self.down52(down51)\n",
    "        down53 = self.down53(down52)\n",
    "        down54 = self.down54(down53)\n",
    "        up11 = self.up11(down54)\n",
    "        up12 = self.up12(torch.cat([up11, down53],1))\n",
    "        up21 = self.up21(up12)\n",
    "        up22 = self.up22(torch.cat([up21, down47],1))\n",
    "        up31 = self.up31(up22)\n",
    "        up32 = self.up32(torch.cat([up31, down31],1))\n",
    "        up41 = self.up41(up32)\n",
    "        up42 = self.up42(up41)\n",
    "        up43 = self.up43(up42)\n",
    "        up44 = self.up44(up43)\n",
    "        up51 = self.up51(torch.cat([up44,input],1))\n",
    "\n",
    "        return up51\n",
    "\n",
    "# CUSTOM DATASET CLASS\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self,data_dir,mask_dir):\n",
    "\n",
    "        self.data_dir=data_dir\n",
    "        self.mask_dir=mask_dir\n",
    "        \n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.data_dir))\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        print(os.path.join(self.data_dir,os.listdir(self.data_dir)[idx]))\n",
    "        im=Image.open(os.path.join(self.data_dir,os.listdir(self.data_dir)[idx])).convert(\"RGB\") #ex : im = l'image qui est dans data_dir/train_imageidx\n",
    "        im_mask=Image.open(os.path.join(self.mask_dir,os.listdir(self.data_dir)[idx].split(\".\")[0] #ex : mask_dir/train_image[premier caractere apres le point]_mask.gif\n",
    "                                     + '_mask.png')).convert(\"RGB\") #L for grayscale\n",
    "        sample={'image':self.to_tensor(array(im)).cuda(),'mask':self.to_tensor(array(im_mask)).cuda()}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING FUNCTION\n",
    "def train(model, train_loader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for i,data in enumerate(train_loader):\n",
    "        image = data['image'] # converting NHWC to NCHW (number of samples, number of channels, height, width)\n",
    "        mask = data['mask']\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(image)\n",
    "\n",
    "        loss = criterion(output, mask)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        #plt.imshow(image.cpu().permute(0, 2, 3, 1).numpy()[0]) #==> Retourne la premiere image du dataset\n",
    "        #fig.add_subplot(222)\n",
    "        #plt.imshow(mask.cpu().permute(0, 2, 3, 1).numpy()[0]) #==> Retourne le premier mask correspondant\n",
    "        #fig.add_subplot(223)\n",
    "        plt.imshow(output.cpu().permute(0, 2, 3, 1).detach().numpy()[0])\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "        #Statistics\n",
    "        print ('image {}'.format(i))\n",
    "        running_loss+=loss\n",
    "        #if i%100==1:\n",
    "        print (\"Loss={}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING THE MODEL\n",
    "def test(model, test_loader, criterion):\n",
    "    model.eval()  # eval mode (batchnormu uses moving mean/variance instead of mini-batch mean/variance)\n",
    "    \n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(test_loader):\n",
    "            image = data['image']\n",
    "            mask = data['mask']\n",
    "\n",
    "            output = model(image)\n",
    "            \n",
    "            loss = criterion(output, mask)\n",
    "            \n",
    "            fig = plt.figure()\n",
    "            plt.imshow(output.cpu().permute(0, 2, 3, 1).detach().numpy()[0])\n",
    "            plt.show()\n",
    "            #Statistics\n",
    "            print ('image {}'.format(i))\n",
    "            test_loss+=loss\n",
    "            #if i%100==1:\n",
    "            print (\"Loss={}\".format(loss))\n",
    "        print(\"Total loss = \", test_loss.item())\n",
    "        print(\"Mean loss = \", test_loss.item()/len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    train_mode = False\n",
    "\n",
    "    # CREATING CUSTOM DATASET AND LOADING DATAS\n",
    "    train_set=CustomDataset(_INPUT_PATH,_TRUTH_PATH)\n",
    "    train_loader=DataLoader(train_set,batch_size=batch_size//2,shuffle=True)\n",
    "    \n",
    "    test_set=CustomDataset(_INPUT_PATH2,_TRUTH_PATH2)\n",
    "    test_loader=DataLoader(test_set,batch_size=batch_size//2)\n",
    "\n",
    "    # CREATING THE MODEL\n",
    "    model = ConvNet().to(device)\n",
    "    \n",
    "    print('\\n-------DEEPSEG-------\\nUsing device ', device, '\\n---------------------\\n\\n')\n",
    "    \n",
    "    # TRAIN MODE\n",
    "    if train_mode:\n",
    "        \n",
    "        # DEFINING LOSS AND OPTIMIZER\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        # TRAINING THE MODEL\n",
    "        for epoch in range(0, num_epochs):\n",
    "            print('Epoch ', epoch+1, '/', num_epochs, '\\n--------------')\n",
    "            train(model, train_loader, criterion, optimizer, epoch)\n",
    "            \n",
    "        # SAVING THE MODEL CHECKPOINT\n",
    "        torch.save(model.state_dict(), 'cnn1.pth')\n",
    "    \n",
    "    # PREDICT / EVALUATION MODE\n",
    "    else:\n",
    "        criterion = nn.MSELoss()\n",
    "        model.load_state_dict(torch.load('cnn1.pth')) #Loading checkpoint file\n",
    "        test(model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------DEEPSEG-------\n",
      "Using device  cuda:0 \n",
      "---------------------\n",
      "\n",
      "\n",
      "./input/to_predict/10.png\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-972361fa1b80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-ff22a9ebeaa6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cnn1.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Loading checkpoint file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-674c1bacf088>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, test_loader, criterion)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640)\n"
     ]
    }
   ],
   "source": [
    "'''SAVE UNE IMAGE'''\n",
    "\n",
    "im_mask=Image.open('./input/truth/0_mask.png').convert('L')\n",
    "img = array(im_mask)\n",
    "\n",
    "'''\n",
    "tenseur = transforms.ToTensor()\n",
    "tenseur(img)\n",
    "print(tenseur.size())\n",
    "'''\n",
    "\n",
    "'''fig = plt.figure()\n",
    "fig.add_subplot(221)\n",
    "plt.imshow(img) #==> Retourne la premiere image du dataset\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "\n",
    "im_to_save = Image.fromarray(img.astype('uint8'), 'L')\n",
    "im_to_save.show()\n",
    "\n",
    "print(img.shape)\n",
    "\n",
    "im_to_save.save('test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (env)",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
